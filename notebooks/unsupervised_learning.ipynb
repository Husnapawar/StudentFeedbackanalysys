{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning for Student Feedback Analysis\n",
    "\n",
    "This notebook demonstrates unsupervised learning techniques for analyzing student feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Add the src directory to the path so we can import our modules\n",
    "sys.path.append('..')\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import project modules\n",
    "from src.utils.data_generator import generate_sample_feedback\n",
    "from src.preprocessing.text_processor import TextProcessor, extract_features\n",
    "from src.models.unsupervised_models import TopicModeler, FeedbackClusterer, DimensionalityReducer\n",
    "from src.evaluation.metrics import evaluate_clustering, evaluate_topic_model\n",
    "from src.visualization.visualizer import plot_topic_wordcloud, plot_cluster_visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load data\n",
    "data_path = '../data/sample_feedback.csv'\n",
    "if not os.path.exists(data_path):\n",
    "    print(\"Generating sample feedback data...\")\n",
    "    df = generate_sample_feedback(n_samples=1000, output_path=data_path)\n",
    "else:\n",
    "    print(\"Loading existing feedback data...\")\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Loaded {len(df)} feedback samples\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Preprocessing and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Preprocess text if not already done\n",
    "if 'processed_text' not in df.columns:\n",
    "    text_processor = TextProcessor(\n",
    "        remove_stopwords=True,\n",
    "        remove_punctuation=True,\n",
    "        lemmatize=True,\n",
    "        stem=False,\n",
    "        lowercase=True\n",
    "    )\n",
    "    df = text_processor.preprocess_dataframe(df, 'feedback_text')\n",
    "\n",
    "# Extract features\n",
    "feature_matrix, vectorizer = extract_features(\n",
    "    df['processed_text'],\n",
    "    method='tfidf',\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(f\"Extracted {len(feature_names)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Perform topic modeling using LDA\n",
    "print(\"Performing LDA topic modeling...\")\n",
    "lda_topic_modeler = TopicModeler(method='lda', n_topics=5)\n",
    "lda_topic_modeler.fit(df['processed_text'])\n",
    "\n",
    "# Get top words for each topic\n",
    "lda_top_words = lda_topic_modeler.get_top_words_per_topic(n_words=10)\n",
    "print(\"\\nTop words for each LDA topic:\")\n",
    "for i, words in enumerate(lda_top_words):\n",
    "    print(f\"Topic {i+1}: {', '.join(words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize LDA topics\n",
    "plot_topic_wordcloud(lda_top_words, topic_names=[f'Topic {i+1}' for i in range(len(lda_top_words))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get topic distribution for each document\n",
    "topic_distribution = lda_topic_modeler.get_topic_distribution(df['processed_text'])\n",
    "\n",
    "# Add dominant topic to the dataframe\n",
    "df_with_topics = df.copy()\n",
    "df_with_topics['dominant_topic'] = topic_distribution['Dominant_Topic']\n",
    "\n",
    "# Display sample rows with their dominant topics\n",
    "print(\"Sample feedback with dominant topics:\")\n",
    "sample_with_topics = df_with_topics[['feedback_text', 'dominant_topic']].head(10)\n",
    "sample_with_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare with NMF topic modeling\n",
    "print(\"Performing NMF topic modeling...\")\n",
    "nmf_topic_modeler = TopicModeler(method='nmf', n_topics=5)\n",
    "nmf_topic_modeler.fit(df['processed_text'])\n",
    "\n",
    "# Get top words for each topic\n",
    "nmf_top_words = nmf_topic_modeler.get_top_words_per_topic(n_words=10)\n",
    "print(\"\\nTop words for each NMF topic:\")\n",
    "for i, words in enumerate(nmf_top_words):\n",
    "    print(f\"Topic {i+1}: {', '.join(words)}\")\n",
    "\n",
    "# Visualize NMF topics\n",
    "plot_topic_wordcloud(nmf_top_words, topic_names=[f'Topic {i+1}' for i in range(len(nmf_top_words))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Reduce dimensionality for clustering\n",
    "print(\"Reducing dimensionality for clustering...\")\n",
    "reducer = DimensionalityReducer(method='svd', n_components=50)\n",
    "reduced_features = reducer.fit_transform(feature_matrix)\n",
    "print(f\"Reduced features shape: {reduced_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Perform K-means clustering\n",
    "print(\"Performing K-means clustering...\")\n",
    "kmeans_clusterer = FeedbackClusterer(method='kmeans', n_clusters=5)\n",
    "kmeans_clusterer.fit(reduced_features)\n",
    "\n",
    "# Evaluate clustering\n",
    "kmeans_results = kmeans_clusterer.evaluate(reduced_features)\n",
    "print(f\"Silhouette Score: {kmeans_results['silhouette_score']:.4f}\")\n",
    "print(\"Cluster sizes:\", kmeans_results['cluster_sizes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize clusters\n",
    "kmeans_labels = kmeans_clusterer.model.labels_\n",
    "plot_cluster_visualization(reduced_features, kmeans_labels, method='tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Add cluster labels to the dataframe\n",
    "df_with_clusters = df.copy()\n",
    "df_with_clusters['cluster'] = kmeans_labels\n",
    "\n",
    "# Analyze clusters\n",
    "print(\"Analyzing clusters...\")\n",
    "for cluster_id in range(5):\n",
    "    cluster_feedback = df_with_clusters[df_with_clusters['cluster'] == cluster_id]['feedback_text']\n",
    "    print(f\"\\nCluster {cluster_id} ({len(cluster_feedback)} samples):\")\n",
    "    print(\"Sample feedback:\")\n",
    "    for feedback in cluster_feedback.head(3):\n",
    "        print(f\"- {feedback}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare with hierarchical clustering\n",
    "print(\"Performing hierarchical clustering...\")\n",
    "hierarchical_clusterer = FeedbackClusterer(method='hierarchical', n_clusters=5)\n",
    "hierarchical_clusterer.fit(reduced_features)\n",
    "\n",
    "# Evaluate clustering\n",
    "hierarchical_results = hierarchical_clusterer.evaluate(reduced_features)\n",
    "print(f\"Silhouette Score: {hierarchical_results['silhouette_score']:.4f}\")\n",
    "print(\"Cluster sizes:\", hierarchical_results['cluster_sizes'])\n",
    "\n",
    "# Visualize clusters\n",
    "hierarchical_labels = hierarchical_clusterer.model.labels_\n",
    "plot_cluster_visualization(reduced_features, hierarchical_labels, method='tsne')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Combining Supervised and Unsupervised Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Combine cluster labels with sentiment and category information\n",
    "combined_df = df.copy()\n",
    "combined_df['cluster'] = kmeans_labels\n",
    "combined_df['dominant_topic'] = topic_distribution['Dominant_Topic']\n",
    "\n",
    "# Analyze relationship between clusters and sentiment\n",
    "cluster_sentiment = pd.crosstab(combined_df['cluster'], combined_df['true_sentiment'])\n",
    "cluster_sentiment_pct = cluster_sentiment.div(cluster_sentiment.sum(axis=1), axis=0)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "cluster_sentiment_pct.plot(kind='bar', stacked=True)\n",
    "plt.title('Sentiment Distribution by Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Percentage')\n",
    "plt.legend(title='Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze relationship between topics and sentiment\n",
    "topic_sentiment = pd.crosstab(combined_df['dominant_topic'], combined_df['true_sentiment'])\n",
    "topic_sentiment_pct = topic_sentiment.div(topic_sentiment.sum(axis=1), axis=0)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "topic_sentiment_pct.plot(kind='bar', stacked=True)\n",
    "plt.title('Sentiment Distribution by Topic')\n",
    "plt.xlabel('Topic')\n",
    "plt.ylabel('Percentage')\n",
    "plt.legend(title='Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze relationship between topics and categories\n",
    "topic_category = pd.crosstab(combined_df['dominant_topic'], combined_df['true_category'])\n",
    "topic_category_pct = topic_category.div(topic_category.sum(axis=1), axis=0)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "topic_category_pct.plot(kind='bar', stacked=True)\n",
    "plt.title('Category Distribution by Topic')\n",
    "plt.xlabel('Topic')\n",
    "plt.ylabel('Percentage')\n",
    "plt.legend(title='Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion and Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings:\n",
    "\n",
    "1. **Topic Modeling**: We identified 5 main topics in the student feedback using both LDA and NMF methods. These topics represent different aspects of the educational experience that students comment on.\n",
    "\n",
    "2. **Clustering**: K-means and hierarchical clustering grouped similar feedback together, revealing patterns that might not be immediately obvious from manual inspection.\n",
    "\n",
    "3. **Combined Analysis**: By combining supervised labels (sentiment, categories) with unsupervised results (clusters, topics), we gained deeper insights into the feedback data:\n",
    "   - Some topics are more associated with positive sentiment than others\n",
    "   - Certain clusters contain feedback predominantly from specific categories\n",
    "   - The relationship between topics and categories helps validate our topic modeling results\n",
    "\n",
    "### Applications:\n",
    "\n",
    "1. **Automated Feedback Categorization**: The models can be used to automatically categorize new feedback\n",
    "2. **Sentiment Tracking**: Track sentiment trends over time for different courses or subjects\n",
    "3. **Topic Discovery**: Identify emerging topics or issues in student feedback\n",
    "4. **Targeted Improvements**: Focus improvement efforts on areas receiving negative feedback\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Model Refinement**: Fine-tune models with more data and parameter optimization\n",
    "2. **Interactive Dashboard**: Develop a dashboard for real-time feedback analysis\n",
    "3. **Temporal Analysis**: Analyze how feedback changes over academic terms\n",
    "4. **Integration**: Integrate with existing educational systems for automated feedback processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
